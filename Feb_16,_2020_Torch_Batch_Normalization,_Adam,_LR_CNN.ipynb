{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feb 16, 2020 Torch Batch Normalization, Adam, LR CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8h51otXe54MZ/NOo8oBJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jikhan-Jeong/2019-Computer-Vision-/blob/master/Feb_16%2C_2020_Torch_Batch_Normalization%2C_Adam%2C_LR_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyrKvrcol_E0",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Feb 16, 2020 Torch Batch Normalization, Adam, LR CNN\n",
        "---\n",
        "* Name: Jikhan Jeong\n",
        "---\n",
        "### Optimization Methods\n",
        "---\n",
        "* SGD\n",
        "* Momentum\n",
        "* Nestrov\n",
        "* Adagrad\n",
        "* Adadelta\n",
        "* Adam\n",
        "* Ref: https://colab.research.google.com/drive/17vefyxasId5GsARxCRdnpPvM9mtQi4gl\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksiIQfs8oUv2",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 1. Preparing\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiV5dNUMlT_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKvoAG7mmiA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256 # 16 height x 16 weight = 256 concantates\n",
        "learning_rate = 0.0002\n",
        "num_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqaSSINIuLN6",
        "colab_type": "text"
      },
      "source": [
        "* Normalization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbwUPUwtmjx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test  = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "\n",
        "# 1 channel so that it requires 1 mean and variance\n",
        "# (with Data Normalization)  mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))]), target_transform=None, download=True)\n",
        "# (with Data Normalization)  mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))]), target_transform=None, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbPxJuQfms2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "087d60b6-60d4-427b-8f23-3d4f7cff6f8c"
      },
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(),    mnist_train.__len__())\n",
        "mnist_test.__getitem__(0)[0].size(),           mnist_test.__len__()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDJCIcORmteW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_train,batch_size=batch_size, shuffle=True,num_workers=2,drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_test,batch_size=batch_size, shuffle=False,num_workers=2,drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4RbG4UYnOUs",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#  2. CNN Model\n",
        "* Plug Batch Normalization in CNN layer (Idea from DenseNet)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duQRyhf3m0ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  CNN Model\n",
        "# https://pytorch.org/docs/stable/nn.html?highlight=batchnorm#torch.nn.BatchNorm2d\n",
        "# nn.BatchNorm2d(x), x input channel number\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "  \n",
        "        super(CNN,self).__init__()\n",
        "  \n",
        "        self.layer = nn.Sequential(   \n",
        "            nn.Conv2d(1,16,3,padding=1),  # 28 x 28, in_channel, out_channel, kernel size = 3 x 3 kernel size\n",
        "            nn.BatchNorm2d(16),           # BatchNorm2d Input channel = 16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,32,3,padding=1), # 28 x 28\n",
        "            nn.BatchNorm2d(32),           # BatchNorm2d Input channel = 32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),            # 14 x 14\n",
        "            nn.Conv2d(32,64,3,padding=1), # 14 x 14\n",
        "            nn.BatchNorm2d(64),           # BatchNorm2d Input channel = 64\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)             #  7 x 7\n",
        "        )\n",
        "  \n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*7*7,100),         # In Feature, out Feature\n",
        "            nn.BatchNorm1d(100),           # BatchNorm1d Input channel = 100\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(batch_size,-1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHqFkrFsnLKT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 3. Loss func & Optimizer\n",
        "---\n",
        "* Adam : change in "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNtoEYEWm_WN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ee8c5dc-f862-412b-90da-6109644fafa9"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "# (SGD optimizer) optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJGWcGdonWo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. StepLR method, decreasing learning rate by using gamma \n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)       \n",
        "\n",
        "# 2. MultiStepLR, decreasing learning rate in step points 10,30,80\n",
        "#scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10,30,80], gamma= 0.1)  \n",
        "\n",
        "# 3. EponentialLR\n",
        "#scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)                             \n",
        "\n",
        "\n",
        "\n",
        "# 4. ReduceLROnPlateau learning rate decreases as there is no improvement\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,threshold=1,patience=1,mode='min')    \n",
        "\n",
        "# Ref: https://pytorch.org/docs/stable/optim.html?highlight=lr_scheduler#torch.optim.lr_scheduler.ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFuXY3BXndAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e97f26f2-d170-469f-b0a5-71481e283c74"
      },
      "source": [
        "print(dir(scheduler))\n",
        "print(dir(optimizer))\n",
        "# Ref: https://www.geeksforgeeks.org/python-dir-function/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_init_is_better', '_reduce_lr', '_reset', 'best', 'cooldown', 'cooldown_counter', 'eps', 'factor', 'in_cooldown', 'is_better', 'last_epoch', 'load_state_dict', 'min_lrs', 'mode', 'mode_worse', 'num_bad_epochs', 'optimizer', 'patience', 'state_dict', 'step', 'threshold', 'threshold_mode', 'verbose']\n",
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add_param_group', 'defaults', 'load_state_dict', 'param_groups', 'state', 'state_dict', 'step', 'zero_grad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VW4nUOXoQM1",
        "colab_type": "text"
      },
      "source": [
        " ---\n",
        " # 4. Train\n",
        " ---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOtBtQTuoNlY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7bf8cd7a-946d-44c8-ed10-29f5467bd58e"
      },
      "source": [
        "for i in range(num_epoch):\n",
        "    # ReduceLRONPlateau using # code: scheduler.step()  \n",
        "    #scheduler.step()  \n",
        "    for j,[image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    # ReduceLRONPlateau only using this part : scheduler.step(loss)   \n",
        "    scheduler.step(loss)      \n",
        "    \n",
        "    if i % 10 == 0:\n",
        "        print(loss)   \n",
        "            \n",
        "    #print(\"Epoch: {}, Learning Rate: {}\".format(i,scheduler.get_lr()))  # Other  schedule not ReduceLRONPlateau\n",
        "    print(\"Epoch: {}, Learning Rate: {}\".format(i,scheduler.optimizer.state_dict()['param_groups'][0]['lr']))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Epoch: 0, Learning Rate: 0.0002\n",
            "Epoch: 1, Learning Rate: 2e-05\n",
            "Epoch: 2, Learning Rate: 2e-05\n",
            "Epoch: 3, Learning Rate: 2.0000000000000003e-06\n",
            "Epoch: 4, Learning Rate: 2.0000000000000003e-06\n",
            "Epoch: 5, Learning Rate: 2.0000000000000004e-07\n",
            "Epoch: 6, Learning Rate: 2.0000000000000004e-07\n",
            "Epoch: 7, Learning Rate: 2.0000000000000007e-08\n",
            "Epoch: 8, Learning Rate: 2.0000000000000007e-08\n",
            "Epoch: 9, Learning Rate: 2.000000000000001e-09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtrv3YU6pJiL",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 5. Test \n",
        "* Batch Normalization + **Adam Optimizaer** : \n",
        "* **Batch Normalization** and **Drop Out** requires **model.eval()**: Accuracy of Test Data: 78.5456771850586\n",
        "* with Normalization: Accuracy of Test Data: 10.436698913574219\n",
        "* without Normalization: Accuracy of Test Data: 10.09615421295166\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEW39xdmpD5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "955e9f47-4e49-49ad-dfc1-14e70c489bb6"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# model.eval() requires for drop out and batch normalization\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image,label in test_loader:\n",
        "      x = image.to(device)\n",
        "      y_= label.to(device)\n",
        "\n",
        "      output = model.forward(x)\n",
        "      _,output_index = torch.max(output,1)\n",
        "\n",
        "      total += label.size(0)\n",
        "      correct += (output_index == y_).sum().float()\n",
        "\n",
        "  print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Test Data: 98.94831848144531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2pkVualzbiK",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# 6. Evaluation: Batch Normalization + Adam is the best way\n",
        "* <font color = blue> Batch Normalization + Adam Optimizaer :  98.94831848144531 </font>\n",
        "* Batch Normalization Accuracy of Test Data: 78.5456771850586 (Increased a lot)\n",
        "* With Normalization: Accuracy of Test Data: 10.436698913574219\n",
        "* Without Normalization: Accuracy of Test Data: 10.09615421295166\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAqlikm3zxrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}